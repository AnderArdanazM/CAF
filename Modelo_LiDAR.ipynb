{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958fd6a5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Con esta configuración, el programa debería funcionar correctamente si los archivos necesarios están en la ruta especificada. Verifica que los datos en `maps` sean accesibles y estén completos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53faf2",
   "metadata": {},
   "source": [
    "Aquí tienes el código completo sin la variable `VERSION`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90156605",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "map mask C:/Users/usuario/Desktop/CAF/v1.0-mini_canbus-001/maps/53992ee3023e5494b90c316c183be829.png does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 160\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 160\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 130\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m():\n\u001b[1;32m--> 130\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mNuScenesObjectDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATAROOT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNúmero de objetos válidos en el dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[31], line 32\u001b[0m, in \u001b[0;36mNuScenesObjectDataset.__init__\u001b[1;34m(self, dataroot)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataroot):\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnusc \u001b[38;5;241m=\u001b[39m \u001b[43mNuScenes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnusc\u001b[38;5;241m.\u001b[39msample:\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\Tecnun\\envs\\lidar_modelo_env\\lib\\site-packages\\nuscenes\\nuscenes.py:116\u001b[0m, in \u001b[0;36mNuScenes.__init__\u001b[1;34m(self, version, dataroot, verbose, map_resolution)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Initialize map mask for each map record.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m map_record \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap:\n\u001b[1;32m--> 116\u001b[0m     map_record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mMapMask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mosp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_record\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilename\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_resolution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_names:\n",
      "File \u001b[1;32mc:\\Users\\usuario\\anaconda3\\Tecnun\\envs\\lidar_modelo_env\\lib\\site-packages\\nuscenes\\utils\\map_mask.py:23\u001b[0m, in \u001b[0;36mMapMask.__init__\u001b[1;34m(self, img_file, resolution)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_file: \u001b[38;5;28mstr\u001b[39m, resolution: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    Init a map mask object that contains the semantic prior (driveable surface and sidewalks) mask.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    :param img_file: File path to map png file.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    :param resolution: Map resolution in meters.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m osp\u001b[38;5;241m.\u001b[39mexists(img_file), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap mask \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(img_file)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m resolution \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly supports down to 0.1 meter resolution.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_file \u001b[38;5;241m=\u001b[39m img_file\n",
      "\u001b[1;31mAssertionError\u001b[0m: map mask C:/Users/usuario/Desktop/CAF/v1.0-mini_canbus-001/maps/53992ee3023e5494b90c316c183be829.png does not exist"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "from nuscenes.utils.geometry_utils import transform_matrix\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "# === CONFIG ===\n",
    "DATAROOT = \"C:/Users/usuario/Desktop/CAF/v1.0-mini_canbus-001/\"\n",
    "NUM_POINTS = 1024\n",
    "NUM_CLASSES = 10\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 8\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === CATEGORÍAS ===\n",
    "CATEGORIES = [\n",
    "    'car', 'truck', 'bus', 'trailer', 'pedestrian',\n",
    "    'motorcycle', 'bicycle', 'construction_vehicle',\n",
    "    'traffic_cone', 'barrier'\n",
    "]\n",
    "CATEGORY2IDX = {cat: i for i, cat in enumerate(CATEGORIES)}\n",
    "\n",
    "# === DATASET ===\n",
    "class NuScenesObjectDataset(Dataset):\n",
    "    def __init__(self, dataroot):\n",
    "        self.nusc = NuScenes(dataroot=dataroot, verbose=False)\n",
    "        self.data = []\n",
    "\n",
    "        for sample in self.nusc.sample:\n",
    "            lidar_token = sample['data']['LIDAR_TOP']\n",
    "            lidar_data = self.nusc.get('sample_data', lidar_token)\n",
    "            lidar_path = os.path.join(dataroot, lidar_data['filename'])\n",
    "            print(f\"Procesando archivo LiDAR: {lidar_path}\")\n",
    "            if not os.path.exists(lidar_path):\n",
    "                print(f\"❌ Archivo LiDAR no encontrado: {lidar_path}\")\n",
    "                continue\n",
    "\n",
    "            pc = LidarPointCloud.from_file(lidar_path).points[:3, :].T  # (N, 3)\n",
    "            print(f\"Puntos LiDAR cargados: {pc.shape}\")\n",
    "\n",
    "            cs = self.nusc.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])\n",
    "            pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "            cs_T = transform_matrix(cs['translation'], Quaternion(cs['rotation']), inverse=False)\n",
    "            pose_T = transform_matrix(pose['translation'], Quaternion(pose['rotation']), inverse=False)\n",
    "            global_T = pose_T @ cs_T\n",
    "            points_h = np.hstack((pc, np.ones((pc.shape[0], 1))))  # (N, 4)\n",
    "            points_global = (global_T @ points_h.T).T[:, :3]\n",
    "\n",
    "            valid = 0\n",
    "            skipped = 0\n",
    "\n",
    "            for ann_token in sample['anns']:\n",
    "                ann = self.nusc.get('sample_annotation', ann_token)\n",
    "                category = ann['category_name'].split('.')[0]\n",
    "                print(f\"Procesando categoría: {category}\")\n",
    "                if category not in CATEGORY2IDX:\n",
    "                    print(f\"Categoría no válida: {category}\")\n",
    "                    continue\n",
    "\n",
    "                center = np.array(ann['translation'])\n",
    "                size = np.array(ann['size']) / 2\n",
    "                rot = Quaternion(ann['rotation']).rotation_matrix\n",
    "                rel = points_global - center\n",
    "                local = rel @ rot\n",
    "\n",
    "                mask = np.all(np.abs(local) <= size, axis=1)\n",
    "                obj_points = points_global[mask]\n",
    "\n",
    "                if obj_points.shape[0] < 20:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                valid += 1\n",
    "\n",
    "                if obj_points.shape[0] >= NUM_POINTS:\n",
    "                    idxs = np.random.choice(obj_points.shape[0], NUM_POINTS, replace=False)\n",
    "                else:\n",
    "                    idxs = np.random.choice(obj_points.shape[0], NUM_POINTS, replace=True)\n",
    "                obj_points = obj_points[idxs]\n",
    "                label = CATEGORY2IDX[category]\n",
    "                self.data.append((obj_points.astype(np.float32), label))\n",
    "\n",
    "            print(f\"Objetos válidos: {valid}, Skipped: {skipped}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pts, label = self.data[idx]\n",
    "        return torch.tensor(pts), torch.tensor(label)\n",
    "\n",
    "# === MODELO POINTNET ===\n",
    "class PointNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.dropout(self.fc2(x))))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# === ENTRENAMIENTO ===\n",
    "def train():\n",
    "    dataset = NuScenesObjectDataset(DATAROOT)\n",
    "    print(\"Número de objetos válidos en el dataset:\", len(dataset))\n",
    "\n",
    "    if len(dataset) == 0:\n",
    "        print(\"❌ ERROR: No se encontraron objetos válidos. Revisa la ruta y el contenido del dataset.\")\n",
    "        return\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "    model = PointNetClassifier(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for pts, labels in loader:\n",
    "            pts, labels = pts.to(DEVICE), labels.to(DEVICE)\n",
    "            pts = pts.transpose(1, 2)  # <-- CORRECCIÓN CLAVE\n",
    "            out = model(pts)\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Loss: {total_loss:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a68210",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Cambios realizados:\n",
    "1. **Eliminación de la variable `VERSION`**: Ahora el código no depende de esta variable.\n",
    "2. **Simplificación de la inicialización del dataset**: Se eliminó el parámetro `version` en la clase `NuScenesObjectDataset`.\n",
    "\n",
    "Este código debería funcionar correctamente si los archivos necesarios están en la ruta especificada. Verifica que los datos en `DATAROOT` sean accesibles y estén completos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar_modelo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
